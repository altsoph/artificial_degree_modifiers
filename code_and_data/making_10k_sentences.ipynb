{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = PreTrainedTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True,return_offsets_mapping = True, max_length=512,truncate=True,add_special_tokens=False,return_token_type_ids=False,return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = {k: v for k, v in sorted(tokenizer_bert.vocab.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21719"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "for item in vocab_sorted.items():\n",
    "    if re.match('[a-z]{2,}$',item[0]):\n",
    "        words.append(item[0])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "adjs = []\n",
    "for ix,word in enumerate(words):\n",
    "    if nlp(word)[0].pos_ == 'NOUN' and len(nouns) < 1000:\n",
    "        nouns.append(nlp(word)[0].text)\n",
    "    elif nlp(word)[0].pos_ == 'ADJ' and len(adjs) < 2000:\n",
    "        adjs.append(nlp(word)[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding gradable adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import textacy\n",
    "import textacy.datasets\n",
    "cw = textacy.datasets.CapitolWords()\n",
    "cw.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_encountered = []\n",
    "unique_adjectives_encountered = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7102bcb5c88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0madjectives_encountered\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/env/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for text,record in cw.records():\n",
    "    processed = nlp(text)\n",
    "    \n",
    "    adjectives_encountered += [token for token in processed if token.text in adjs]\n",
    "    \n",
    "    for token in processed:\n",
    "        if token.text in adjs:\n",
    "            unique_adjectives_encountered |= set([token.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316114, 1573)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjectives_encountered),len(unique_adjectives_encountered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradable = defaultdict(int)\n",
    "non_gradable = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = ['somewhat','very','really','extremely','rather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in adjectives_encountered:\n",
    "    if len([x for x in adj.children if x.text in modifiers])>0:\n",
    "        gradable[adj.text] += 1\n",
    "    else:\n",
    "        non_gradable[adj.text]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in unique_adjectives_encountered:\n",
    "    toAdd = []\n",
    "\n",
    "    toAdd.append(gradable[adj])\n",
    "    toAdd.append(non_gradable[adj])\n",
    "    combined[adj] = toAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = defaultdict(list)\n",
    "for adj in combined:\n",
    "    occurences = sum(combined[adj])\n",
    "    gradability_score = round(float((combined[adj][0])/occurences) * 100, 3)\n",
    "    if occurences > 100 and gradability_score > 0.6:\n",
    "        adjs[adj] = gradability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gradable_adjectives.txt', 'w') as f:\n",
    "    for item in adjs:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for noun in nouns:\n",
    "    for adj in adjs:\n",
    "        sentences.append('The '+noun+' is '+adj+'.')\n",
    "        sentences.append('The '+noun+' are '+adj+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The time is valuable.',\n",
       " 'The time are valuable.',\n",
       " 'The time is rare.',\n",
       " 'The time are rare.',\n",
       " 'The time is successful.',\n",
       " 'The time are successful.',\n",
       " 'The time is sorry.',\n",
       " 'The time are sorry.',\n",
       " 'The time is broad.',\n",
       " 'The time are broad.']"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by GPT perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import GPT2LMHeadModel, GPT2Tokenizer\n",
    "device = torch.device('cuda:0')\n",
    "model_id = 'gpt2'\n",
    "model_gpt = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer_gpt = GPT2Tokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gpt(sentence):\n",
    "    tokens = [\"[CLS]\"] + tokenizer_gpt.tokenize(sentence)\n",
    "    tokens_ids = tokenizer_gpt.convert_tokens_to_ids(tokens)\n",
    "    tokens_ids = torch.tensor([tokens_ids,], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_gpt(tokens_ids, lm_labels=tokens_ids)\n",
    "        log_likelihood = outputs.item()\n",
    "    return np.exp(log_likelihood) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {}\n",
    "for sentence in sentences:\n",
    "    pairs[sentence] = process_gpt(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104082</th>\n",
       "      <td>The reason is simple.</td>\n",
       "      <td>32.092901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145282</th>\n",
       "      <td>The answer is simple.</td>\n",
       "      <td>33.160138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191283</th>\n",
       "      <td>The rules are simple.</td>\n",
       "      <td>35.773233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96482</th>\n",
       "      <td>The plan is simple.</td>\n",
       "      <td>36.188385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67282</th>\n",
       "      <td>The idea is simple.</td>\n",
       "      <td>37.175624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74621</th>\n",
       "      <td>The wouldn are junior.</td>\n",
       "      <td>17539.405174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19341</th>\n",
       "      <td>The wasn are richest.</td>\n",
       "      <td>18833.300436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74573</th>\n",
       "      <td>The wouldn are rural.</td>\n",
       "      <td>19602.368611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19421</th>\n",
       "      <td>The wasn are junior.</td>\n",
       "      <td>20574.691978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19373</th>\n",
       "      <td>The wasn are rural.</td>\n",
       "      <td>21252.049206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sentence    perplexity\n",
       "104082   The reason is simple.     32.092901\n",
       "145282   The answer is simple.     33.160138\n",
       "191283   The rules are simple.     35.773233\n",
       "96482      The plan is simple.     36.188385\n",
       "67282      The idea is simple.     37.175624\n",
       "...                        ...           ...\n",
       "74621   The wouldn are junior.  17539.405174\n",
       "19341    The wasn are richest.  18833.300436\n",
       "74573    The wouldn are rural.  19602.368611\n",
       "19421     The wasn are junior.  20574.691978\n",
       "19373      The wasn are rural.  21252.049206\n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(pairs, orient='index').reset_index()\n",
    "df = df.rename(columns={\"index\": \"sentence\", 0: \"perplexity\"})\n",
    "df.sort_values(by='perplexity', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='perplexity', ascending=True).to_csv('/home/lisa/hobbies/modifiers_all.csv')\n",
    "df.sort_values(by='perplexity', ascending=True).head(10000).to_csv('/home/lisa/hobbies/modifiers_top10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
